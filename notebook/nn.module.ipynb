{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Intro\n",
    "1. 这个父类`nn.module`模块就像一个树的head node一样，很多方法都要继承这个父类，比如loss或者conv等结构\n",
    "2. 调用访问的两种方法:\n",
    "    - 使用list: `list(net.parameters())`，想访问第0层就`list(net.parameters())[0]`\n",
    "    - 使用dict: `dict(net.named_parameters()).items()`\n",
    "# 2. children\n",
    "1. 只有“直系亲属”才能叫做children，比如下面的`Sequential`，但是所有的relu这些，都是一个`module`\n",
    "2. 根节点的含义还体现在`net.train()`，通过根节点进入train模式，它继承的所有node都会进入train模式"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class BasicNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicNet,self).__init__()\n",
    "        self.net = nn.Linear(4,3)\n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def init_(self):\n",
    "        super(Net,self).__init__=()\n",
    "        # children\n",
    "        self.net = nn.Sequential(BasicNet(),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(3,2))\n",
    "    def forward(self,x):\n",
    "        return self.net(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 加载自定义的class\n",
    "1. 只有`class`才可以写进`Sequential`里面，`function`不行，如果某个操作，比如下面的`flatten`，只有`function`，没有`class`，那么可以**自己写**："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten,self).__init__()\n",
    "    def forward(self,input):\n",
    "        return input.view(input.size(0),-1)\n",
    "\n",
    "class TestNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestNet,self).__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(1,16,kernel_size=1,stride=1,padding=1),\n",
    "                                nn.MaxPool2d(2,2),\n",
    "                                # 引入自定义flatten\n",
    "                                Flatten(),\n",
    "                                nn.Linear(1*14*14,10))\n",
    "    def forward(self,x):\n",
    "        return self.net(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. 同理，可以设计更复杂的操作，下面就是自定义了linear层\n",
    "    - `nn.Parameter`是一个包装器，对tensor进行包装，然后自动加入计算图，**并且加到`nn.parameters()`中去，从而可以被优化器进行自动优化**\n",
    "    - `requires_grad = True`设置不设置都ok"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self,inp,outp):\n",
    "        super(MyLinear,self).__init__()\n",
    "\n",
    "        self.w=nn.Parameter(torch.randn(outp,inp))\n",
    "        self.b=nn.Parameter(torch.randn(outp))\n",
    "    def forward(self,x):\n",
    "        x = x @ self.w.t() + self.b\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
